{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/larkin/code/smart-rec-ass/.smart-rec-env/lib/python3.8/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import json\n",
    "import re\n",
    "import copy\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from modules.ml_tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, data, oos_data = process_text(spacy_lib_str = \"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = [d[\"level\"] for d in data if \"level\" in d.keys()]\n",
    "titles = [d[\"title\"] for d in data if \"title\" in d.keys()]\n",
    "\n",
    "model_data = [e for e in embeddings if e[\"level\"] is not None]\n",
    "missing_level_data = [e for e in embeddings if e[\"level\"] is None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total jobs: 141\n",
      "Missing levels: (53.19% of total)\n",
      "Unique levels:\n",
      "- Internship\n",
      "- Entry Level\n",
      "- Mid Level\n",
      "- Senior Level\n"
     ]
    }
   ],
   "source": [
    "# Calculate statistics\n",
    "total_jobs = len(data)\n",
    "missing_levels_size = len(missing_level_data)\n",
    "unique_levels = len(set(levels))\n",
    "\n",
    "# Print statistics\n",
    "print(f\"Total jobs: {total_jobs}\")\n",
    "print(f\"Missing levels: ({missing_levels_size / total_jobs * 100:.2f}% of total)\")\n",
    "\n",
    "# Print unique levels\n",
    "print(\"Unique levels:\")\n",
    "for level in set(levels):\n",
    "    print(f\"- {INVERT_LVL_DIC[level]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The total number of jobs in the dataset is 141.\n",
    "- The missing levels percentage is 53.19% of total. This indicates that approximately half of the jobs in the dataset have missing levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-Sample Accuracy (Heuristics Only): 0.8846153846153846\n",
      "Keyword Heuristic Coverage: 0.36879432624113473\n"
     ]
    }
   ],
   "source": [
    "# What is the coverage and accuracy if we apply heuristic rules?\n",
    "infer_data = infer_lvl_from_rules(oos_data)\n",
    "in_samp_data = infer_lvl_from_rules(model_data)\n",
    "\n",
    "data_heu_pred = [i for i in in_samp_data if i[\"level_inf\"] is not None]\n",
    "data_heu_correct = [i for i in data_heu_pred if i[\"level\"] == i[\"level_inf\"]]\n",
    "\n",
    "acc_heu = len(data_heu_correct)/len(data_heu_pred) # in sample accuracy using only heuristics\n",
    "\n",
    "# Keyword heuristic coverage\n",
    "coverage_heu = len(data_heu_pred)/len(in_samp_data) \n",
    "\n",
    "print(\"In-Sample Accuracy (Heuristics Only):\", acc_heu)\n",
    "print(\"Keyword Heuristic Coverage:\", coverage_heu)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using only heuristic rules in `modules.ml_tools.heuristic_rules` function, we are able to obtain 88% accuracy, with coverage over 36% of the data. The rest we will not need to use another model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:55:20] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGB Training Accuracy: 0.87\n",
      "XGB Testing Accuracy: 0.38\n"
     ]
    }
   ],
   "source": [
    "xg_model, accuracy_tr, accuracy_test = run_xgboost_pipeline(in_samp_data)\n",
    "in_samp_acc = in_sample_accuracy(in_samp_data, xg_model)\n",
    "\n",
    "print(f\"XGB Training Accuracy: {accuracy_tr:.2f}\")\n",
    "print(f\"XGB Testing Accuracy: {accuracy_test:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_data = run_inference_oos(oos_data, xg_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment data, with heuristic predictions\n",
    "infer_data_w_lab = [i for i in infer_data if i[\"level_inf\"] is not None]\n",
    "\n",
    "for i in infer_data_w_lab:\n",
    "    i[\"level\"] = i[\"level_inf\"]\n",
    "\n",
    "in_samp_data_augmented = in_samp_data + infer_data_w_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = np.array([d[\"doc_vec\"].vector for d in in_samp_data_augmented])\n",
    "data_y = np.array([d[\"level\"] for d in in_samp_data_augmented])\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:22:02] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.8931297709923665 0.48484848484848486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/larkin/code/smart-rec-ass/.smart-rec-env/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "model, accuracy_tr, accuracy_test = run_xgboost(X_train, X_test, y_train, y_test)\n",
    "print(accuracy_tr, accuracy_test)\n",
    "# no significant improvements with augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in infer_data:\n",
    "    if d['level_inf'] is None:\n",
    "        d['level_inf'] = model.predict(np.array([d[\"doc_vec\"].vector]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in in_samp_data:\n",
    "    if d['level_inf'] is None:\n",
    "        d['level_inf'] = model.predict(np.array([d[\"doc_vec\"].vector]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8368794326241135"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hiearchical model accuracy on in sample data\n",
    "data_insamp_correct = [i for i in in_samp_data if i[\"level\"] == i[\"level_inf\"]]\n",
    "len(data_insamp_correct)/len(in_samp_data) # in sample accuracy using only heuristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".smart-rec-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
